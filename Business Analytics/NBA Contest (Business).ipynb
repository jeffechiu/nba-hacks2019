{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character in identifier (<ipython-input-20-37d4f666c4e5>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-20-37d4f666c4e5>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    input=’content’, encoding=’utf-8’, decode_error=’strict’, strip_accents=None,\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character in identifier\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "text = ''\n",
    "X = vectorizer.fit_transform(text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictors\n",
    "X_raw = np.random.random(100*9)\n",
    "X_raw = np.reshape(X_raw, (100, 9))\n",
    "\n",
    "# Standardize the predictors\n",
    "scaler = StandardScaler().fit(X_raw)\n",
    "X = scaler.transform(X_raw)\n",
    "\n",
    "# Add an intercept column to the model.\n",
    "X = np.abs(np.concatenate((np.ones((X.shape[0],1)), X), axis=1))\n",
    "\n",
    "# Define my \"true\" beta coefficients\n",
    "\n",
    "beta = np.array([2,6,7,3,5,7,1,2,2,8])\n",
    "\n",
    "# Y = Xb\n",
    "Y_true = np.matmul(X,beta)\n",
    "\n",
    "# Observed data with noise\n",
    "Y = Y_true*np.exp(np.random.normal(loc=0.0, scale=0.2, size=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred, sample_weights=None):\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    \n",
    "    if np.any(y_true==0):\n",
    "        print(\"Found zeroes in y_true. MAPE undefined. Removing from set...\")\n",
    "        idx = np.where(y_true==0)\n",
    "        y_true = np.delete(y_true, idx)\n",
    "        y_pred = np.delete(y_pred, idx)\n",
    "        if type(sample_weights) != type(None):\n",
    "            sample_weights = np.array(sample_weights)\n",
    "            sample_weights = np.delete(sample_weights, idx)\n",
    "        \n",
    "    if type(sample_weights) == type(None):\n",
    "        return(np.mean(np.abs((y_true - y_pred) / y_true)) * 100)\n",
    "    else:\n",
    "        sample_weights = np.array(sample_weights)\n",
    "        assert len(sample_weights) == len(y_true)\n",
    "        return(100/sum(sample_weights)*np.dot(\n",
    "                sample_weights, (np.abs((y_true - y_pred) / y_true))\n",
    "        ))\n",
    "    \n",
    "loss_function = mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.26369843  5.08958273  8.49793391  1.82781447  2.7843254   6.40457697\n",
      " -0.68349731  0.63699135  2.31620298  9.92712145]\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "def objective_function(beta, X, Y):\n",
    "    error = loss_function(np.matmul(X,beta), Y)\n",
    "    return(error)\n",
    "\n",
    "# You must provide a starting point at which to initialize\n",
    "# the parameter search space\n",
    "beta_init = np.array([1]*X.shape[1])\n",
    "result = minimize(objective_function, beta_init, args=(X,Y),\n",
    "                  method='BFGS', options={'maxiter': 500})\n",
    "\n",
    "# The optimal values for the input parameters are stored\n",
    "# in result.x\n",
    "beta_hat = result.x\n",
    "print(beta_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.881933363538634"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_function(np.matmul(X,beta_hat), Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.71511879,  5.31496938,  8.68726636,  1.93584099,  2.71881164,\n",
       "        6.43907179, -0.59309471,  0.75186615,  2.26318172,  9.90273579])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CustomLinearModel:\n",
    "    \"\"\"\n",
    "    Linear model: Y = XB, fit by minimizing the provided loss_function\n",
    "    with L2 regularization\n",
    "    \"\"\"\n",
    "    def __init__(self, loss_function=mean_absolute_percentage_error, \n",
    "                 X=None, Y=None, sample_weights=None, beta_init=None, \n",
    "                 regularization=0.00012):\n",
    "        self.regularization = regularization\n",
    "        self.beta = None\n",
    "        self.loss_function = loss_function\n",
    "        self.sample_weights = sample_weights\n",
    "        self.beta_init = beta_init\n",
    "        \n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "            \n",
    "    \n",
    "    def predict(self, X):\n",
    "        prediction = np.matmul(X, self.beta)\n",
    "        return(prediction)\n",
    "\n",
    "    def model_error(self):\n",
    "        error = self.loss_function(\n",
    "            self.predict(self.X), self.Y, sample_weights=self.sample_weights\n",
    "        )\n",
    "        return(error)\n",
    "    \n",
    "    def l2_regularized_loss(self, beta):\n",
    "        self.beta = beta\n",
    "        return(self.model_error() + \\\n",
    "               sum(self.regularization*np.array(self.beta)**2))\n",
    "    \n",
    "    def fit(self, maxiter=250):        \n",
    "        # Initialize beta estimates (you may need to normalize\n",
    "        # your data and choose smarter initialization values\n",
    "        # depending on the shape of your loss function)\n",
    "        if type(self.beta_init)==type(None):\n",
    "            # set beta_init = 1 for every feature\n",
    "            self.beta_init = np.array([1]*self.X.shape[1])\n",
    "        else: \n",
    "            # Use provided initial values\n",
    "            pass\n",
    "            \n",
    "        if self.beta!=None and all(self.beta_init == self.beta):\n",
    "            print(\"Model already fit once; continuing fit with more itrations.\")\n",
    "            \n",
    "        res = minimize(self.l2_regularized_loss, self.beta_init,\n",
    "                       method='BFGS', options={'maxiter': 500})\n",
    "        self.beta = res.x\n",
    "        self.beta_init = self.beta\n",
    "\n",
    "l2_mape_model = CustomLinearModel(\n",
    "    loss_function=mean_absolute_percentage_error,\n",
    "    X=X, Y=Y, regularization=0.00012\n",
    ")\n",
    "l2_mape_model.fit()\n",
    "l2_mape_model.beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1a255e13c8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(l2_mape_model.predict(X), Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Used to cross-validate models and identify optimal lambda\n",
    "class CustomCrossValidator:\n",
    "    \n",
    "    \"\"\"\n",
    "    Cross validates arbitrary model using MAPE criterion on\n",
    "    list of lambdas.\n",
    "    \"\"\"\n",
    "    def __init__(self, X, Y, ModelClass,\n",
    "                 sample_weights=None,\n",
    "                 loss_function=mean_absolute_percentage_error):\n",
    "        \n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.ModelClass = ModelClass\n",
    "        self.loss_function = loss_function\n",
    "        self.sample_weights = sample_weights\n",
    "    \n",
    "    def cross_validate(self, lambdas, num_folds=10):\n",
    "        \"\"\"\n",
    "        lambdas: set of regularization parameters to try\n",
    "        num_folds: number of folds to cross-validate against\n",
    "        \"\"\"\n",
    "        \n",
    "        self.lambdas = lambdas\n",
    "        self.cv_scores = []\n",
    "        X = self.X\n",
    "        Y = self.Y \n",
    "        \n",
    "        # Beta values are not likely to differ dramatically\n",
    "        # between differnt folds. Keeping track of the estimated\n",
    "        # beta coefficients and passing them as starting values\n",
    "        # to the .fit() operator on our model class can significantly\n",
    "        # lower the time it takes for the minimize() function to run\n",
    "        beta_init = None\n",
    "        \n",
    "        for lam in self.lambdas:\n",
    "            print(\"Lambda: {}\".format(lam))\n",
    "            \n",
    "            # Split data into training/holdout sets\n",
    "            kf = KFold(n_splits=num_folds, shuffle=True)\n",
    "            kf.get_n_splits(X)\n",
    "            \n",
    "            # Keep track of the error for each holdout fold\n",
    "            k_fold_scores = []\n",
    "            \n",
    "            # Iterate over folds, using k-1 folds for training\n",
    "            # and the k-th fold for validation\n",
    "            f = 1\n",
    "            for train_index, test_index in kf.split(X):\n",
    "                # Training data\n",
    "                CV_X = X[train_index,:]\n",
    "                CV_Y = Y[train_index]\n",
    "                CV_weights = None\n",
    "                if type(self.sample_weights) != type(None):\n",
    "                    CV_weights = self.sample_weights[train_index]\n",
    "                \n",
    "                # Holdout data\n",
    "                holdout_X = X[test_index,:]\n",
    "                holdout_Y = Y[test_index]\n",
    "                holdout_weights = None\n",
    "                if type(self.sample_weights) != type(None):\n",
    "                    holdout_weights = self.sample_weights[test_index]\n",
    "                \n",
    "                # Fit model to training sample\n",
    "                lambda_fold_model = self.ModelClass(\n",
    "                    regularization=lam,\n",
    "                    X=CV_X,\n",
    "                    Y=CV_Y,\n",
    "                    sample_weights=CV_weights,\n",
    "                    beta_init=beta_init,\n",
    "                    loss_function=self.loss_function\n",
    "                )\n",
    "                lambda_fold_model.fit()\n",
    "                \n",
    "                # Extract beta values to pass as beta_init \n",
    "                # to speed up estimation of the next fold\n",
    "                beta_init = lambda_fold_model.beta\n",
    "                \n",
    "                # Calculate holdout error\n",
    "                fold_preds = lambda_fold_model.predict(holdout_X)\n",
    "                fold_mape = mean_absolute_percentage_error(\n",
    "                    holdout_Y, fold_preds, sample_weights=holdout_weights\n",
    "                )\n",
    "                k_fold_scores.append(fold_mape)\n",
    "                print(\"Fold: {}. Error: {}\".format( f, fold_mape))\n",
    "                f += 1\n",
    "            \n",
    "            # Error associated with each lambda is the average\n",
    "            # of the errors across the k folds\n",
    "            lambda_scores = np.mean(k_fold_scores)\n",
    "            print(\"LAMBDA AVERAGE: {}\".format(lambda_scores))\n",
    "            self.cv_scores.append(lambda_scores)\n",
    "        \n",
    "        # Optimal lambda is that which minimizes the cross-validation error\n",
    "        self.lambda_star_index = np.argmin(self.cv_scores)\n",
    "        self.lambda_star = self.lambdas[self.lambda_star_index]\n",
    "        print(\"\\n\\n**OPTIMAL LAMBDA: {}**\".format(self.lambda_star))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda: 1\n",
      "Fold: 1. Error: 27.611043437826126\n",
      "Fold: 2. Error: 34.70856972567844\n",
      "Fold: 3. Error: 32.23682865171843\n",
      "Fold: 4. Error: 32.93096144537122\n",
      "Fold: 5. Error: 35.524295395923225\n",
      "LAMBDA AVERAGE: 32.60233973130349\n",
      "Lambda: 0.1\n",
      "Fold: 1. Error: 14.485593262785212\n",
      "Fold: 2. Error: 16.929303669184982\n",
      "Fold: 3. Error: 16.963351251097038\n",
      "Fold: 4. Error: 16.832598010696646\n",
      "Fold: 5. Error: 14.494949859697293\n",
      "LAMBDA AVERAGE: 15.941159210692234\n",
      "Lambda: 0.01\n",
      "Fold: 1. Error: 13.29104128000923\n",
      "Fold: 2. Error: 13.368084371129015\n",
      "Fold: 3. Error: 20.38849277576705\n",
      "Fold: 4. Error: 17.57683924661707\n",
      "Fold: 5. Error: 17.269230288186993\n",
      "LAMBDA AVERAGE: 16.37873759234187\n",
      "Lambda: 0.001\n",
      "Fold: 1. Error: 14.797762161282174\n",
      "Fold: 2. Error: 15.945272054963642\n",
      "Fold: 3. Error: 14.725059000702798\n",
      "Fold: 4. Error: 15.469369660824734\n",
      "Fold: 5. Error: 15.732011042206715\n",
      "LAMBDA AVERAGE: 15.333894783996012\n",
      "Lambda: 0.0001\n",
      "Fold: 1. Error: 14.670276685185904\n",
      "Fold: 2. Error: 16.257686506790712\n",
      "Fold: 3. Error: 16.45746117270353\n",
      "Fold: 4. Error: 19.60910909281234\n",
      "Fold: 5. Error: 13.649179698998074\n",
      "LAMBDA AVERAGE: 16.12874263129811\n",
      "Lambda: 1e-05\n",
      "Fold: 1. Error: 16.11978138328853\n",
      "Fold: 2. Error: 16.071147883780355\n",
      "Fold: 3. Error: 20.0002103377423\n",
      "Fold: 4. Error: 17.400147530709837\n",
      "Fold: 5. Error: 15.537231322729633\n",
      "LAMBDA AVERAGE: 17.02570369165013\n",
      "Lambda: 1e-06\n",
      "Fold: 1. Error: 16.313316158716194\n",
      "Fold: 2. Error: 16.155657953732277\n",
      "Fold: 3. Error: 14.020871892167373\n",
      "Fold: 4. Error: 12.964734990282611\n",
      "Fold: 5. Error: 15.314756610653554\n",
      "LAMBDA AVERAGE: 14.953867521110402\n",
      "\n",
      "\n",
      "**OPTIMAL LAMBDA: 1e-06**\n"
     ]
    }
   ],
   "source": [
    "# User must specify lambdas over which to search\n",
    "lambdas = [1, 0.1, 0.01, 0.001, 0.0001, 0.00001, 0.000001]\n",
    "\n",
    "cross_validator = CustomCrossValidator(\n",
    "    X, Y, CustomLinearModel,\n",
    "    loss_function=mean_absolute_percentage_error\n",
    ")\n",
    "cross_validator.cross_validate(lambdas, num_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
