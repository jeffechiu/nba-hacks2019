{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "text = ''\n",
    "#X = vectorizer.fit_transform(text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictors\n",
    "X_raw = np.random.random(100*9)\n",
    "X_raw = np.reshape(X_raw, (100, 9))\n",
    "\n",
    "# Standardize the predictors\n",
    "scaler = StandardScaler().fit(X_raw)\n",
    "X = scaler.transform(X_raw)\n",
    "\n",
    "# Add an intercept column to the model.\n",
    "X = np.abs(np.concatenate((np.ones((X.shape[0],1)), X), axis=1))\n",
    "\n",
    "# Define my \"true\" beta coefficients\n",
    "\n",
    "beta = np.array([2,6,7,3,5,7,1,2,2,8])\n",
    "\n",
    "# Y = Xb\n",
    "Y_true = np.matmul(X,beta)\n",
    "\n",
    "# Observed data with noise\n",
    "Y = Y_true*np.exp(np.random.normal(loc=0.0, scale=0.2, size=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred, sample_weights=None):\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    \n",
    "    if np.any(y_true==0):\n",
    "        print(\"Found zeroes in y_true. MAPE undefined. Removing from set...\")\n",
    "        idx = np.where(y_true==0)\n",
    "        y_true = np.delete(y_true, idx)\n",
    "        y_pred = np.delete(y_pred, idx)\n",
    "        if type(sample_weights) != type(None):\n",
    "            sample_weights = np.array(sample_weights)\n",
    "            sample_weights = np.delete(sample_weights, idx)\n",
    "        \n",
    "    if type(sample_weights) == type(None):\n",
    "        return(np.mean(np.abs((y_true - y_pred) / y_true)) * 100)\n",
    "    else:\n",
    "        sample_weights = np.array(sample_weights)\n",
    "        assert len(sample_weights) == len(y_true)\n",
    "        return(100/sum(sample_weights)*np.dot(\n",
    "                sample_weights, (np.abs((y_true - y_pred) / y_true))\n",
    "        ))\n",
    "    \n",
    "loss_function = mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.4868193  5.53422755 5.14835529 2.6725419  6.2462664  8.95779472\n",
      " 0.0594618  2.35693877 4.00130242 6.66220933]\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "def objective_function(beta, X, Y):\n",
    "    error = loss_function(np.matmul(X,beta), Y)\n",
    "    return(error)\n",
    "\n",
    "# You must provide a starting point at which to initialize\n",
    "# the parameter search space\n",
    "beta_init = np.array([1]*X.shape[1])\n",
    "result = minimize(objective_function, beta_init, args=(X,Y),\n",
    "                  method='BFGS', options={'maxiter': 500})\n",
    "\n",
    "# The optimal values for the input parameters are stored\n",
    "# in result.x\n",
    "beta_hat = result.x\n",
    "print(beta_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.02197506106436"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_function(np.matmul(X,beta_hat), Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.00695273, 5.77328992, 5.1467542 , 2.8574369 , 6.33745381,\n",
       "       8.92055823, 0.02872505, 2.48120007, 4.2133976 , 6.40475277])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "class CustomLinearModel:\n",
    "    \"\"\"\n",
    "    Linear model: Y = XB, fit by minimizing the provided loss_function\n",
    "    with L2 regularization\n",
    "    \"\"\"\n",
    "    def __init__(self, loss_function=mean_absolute_percentage_error, \n",
    "                 X=None, Y=None, sample_weights=None, beta_init=None, \n",
    "                 regularization=0.00012):\n",
    "        self.regularization = regularization\n",
    "        self.beta = None\n",
    "        self.loss_function = loss_function\n",
    "        self.sample_weights = sample_weights\n",
    "        self.beta_init = beta_init\n",
    "        \n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "            \n",
    "    \n",
    "    def predict(self, X):\n",
    "        prediction = np.matmul(X, self.beta)\n",
    "        return(prediction)\n",
    "\n",
    "    def model_error(self):\n",
    "        error = self.loss_function(\n",
    "            self.predict(self.X), self.Y, sample_weights=self.sample_weights\n",
    "        )\n",
    "        return(error)\n",
    "    \n",
    "    def l2_regularized_loss(self, beta):\n",
    "        self.beta = beta\n",
    "        return(self.model_error() + \\\n",
    "               sum(self.regularization*np.array(self.beta)**2))\n",
    "    \n",
    "    \n",
    "    \n",
    "    def fit(self, maxiter=250):        \n",
    "        # Initialize beta estimates (you may need to normalize\n",
    "        # your data and choose smarter initialization values\n",
    "        # depending on the shape of your loss function)\n",
    "        if type(self.beta_init)==type(None):\n",
    "            # set beta_init = 1 for every feature\n",
    "            self.beta_init = np.array([1]*self.X.shape[1])\n",
    "        else: \n",
    "            # Use provided initial values\n",
    "            pass\n",
    "            \n",
    "        if self.beta!=None and all(self.beta_init == self.beta):\n",
    "            print(\"Model already fit once; continuing fit with more itrations.\")\n",
    "            \n",
    "        res = minimize(self.l2_regularized_loss, self.beta_init,\n",
    "                       method='BFGS', options={'maxiter': 500})\n",
    "        self.beta = res.x\n",
    "        self.beta_init = self.beta\n",
    "\n",
    "l2_mape_model = CustomLinearModel(\n",
    "    loss_function=mean_absolute_percentage_error,\n",
    "    X=X, Y=Y, regularization=0.00012\n",
    ")\n",
    "\n",
    "l2_mape_model.fit()\n",
    "l2_mape_model.beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2593159ada0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(l2_mape_model.predict(X), Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Used to cross-validate models and identify optimal lambda\n",
    "class CustomCrossValidator:\n",
    "    \n",
    "    \"\"\"\n",
    "    Cross validates arbitrary model using MAPE criterion on\n",
    "    list of lambdas.\n",
    "    \"\"\"\n",
    "    def __init__(self, X, Y, ModelClass,\n",
    "                 sample_weights=None,\n",
    "                 loss_function=mean_absolute_percentage_error):\n",
    "        \n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.ModelClass = ModelClass\n",
    "        self.loss_function = loss_function\n",
    "        self.sample_weights = sample_weights\n",
    "    \n",
    "    def cross_validate(self, lambdas, num_folds=10):\n",
    "        \"\"\"\n",
    "        lambdas: set of regularization parameters to try\n",
    "        num_folds: number of folds to cross-validate against\n",
    "        \"\"\"\n",
    "        \n",
    "        self.lambdas = lambdas\n",
    "        self.cv_scores = []\n",
    "        X = self.X\n",
    "        Y = self.Y \n",
    "        \n",
    "        # Beta values are not likely to differ dramatically\n",
    "        # between differnt folds. Keeping track of the estimated\n",
    "        # beta coefficients and passing them as starting values\n",
    "        # to the .fit() operator on our model class can significantly\n",
    "        # lower the time it takes for the minimize() function to run\n",
    "        beta_init = None\n",
    "        \n",
    "        for lam in self.lambdas:\n",
    "            print(\"Lambda: {}\".format(lam))\n",
    "            \n",
    "            # Split data into training/holdout sets\n",
    "            kf = KFold(n_splits=num_folds, shuffle=True)\n",
    "            kf.get_n_splits(X)\n",
    "            \n",
    "            # Keep track of the error for each holdout fold\n",
    "            k_fold_scores = []\n",
    "            \n",
    "            # Iterate over folds, using k-1 folds for training\n",
    "            # and the k-th fold for validation\n",
    "            f = 1\n",
    "            for train_index, test_index in kf.split(X):\n",
    "                # Training data\n",
    "                CV_X = X[train_index,:]\n",
    "                CV_Y = Y[train_index]\n",
    "                CV_weights = None\n",
    "                if type(self.sample_weights) != type(None):\n",
    "                    CV_weights = self.sample_weights[train_index]\n",
    "                \n",
    "                # Holdout data\n",
    "                holdout_X = X[test_index,:]\n",
    "                holdout_Y = Y[test_index]\n",
    "                holdout_weights = None\n",
    "                if type(self.sample_weights) != type(None):\n",
    "                    holdout_weights = self.sample_weights[test_index]\n",
    "                \n",
    "                # Fit model to training sample\n",
    "                lambda_fold_model = self.ModelClass(\n",
    "                    regularization=lam,\n",
    "                    X=CV_X,\n",
    "                    Y=CV_Y,\n",
    "                    sample_weights=CV_weights,\n",
    "                    beta_init=beta_init,\n",
    "                    loss_function=self.loss_function\n",
    "                )\n",
    "                lambda_fold_model.fit()\n",
    "                \n",
    "                # Extract beta values to pass as beta_init \n",
    "                # to speed up estimation of the next fold\n",
    "                beta_init = lambda_fold_model.beta\n",
    "                \n",
    "                # Calculate holdout error\n",
    "                fold_preds = lambda_fold_model.predict(holdout_X)\n",
    "                fold_mape = mean_absolute_percentage_error(\n",
    "                    holdout_Y, fold_preds, sample_weights=holdout_weights\n",
    "                )\n",
    "                k_fold_scores.append(fold_mape)\n",
    "                print(\"Fold: {}. Error: {}\".format( f, fold_mape))\n",
    "                f += 1\n",
    "            \n",
    "            # Error associated with each lambda is the average\n",
    "            # of the errors across the k folds\n",
    "            lambda_scores = np.mean(k_fold_scores)\n",
    "            print(\"LAMBDA AVERAGE: {}\".format(lambda_scores))\n",
    "            self.cv_scores.append(lambda_scores)\n",
    "        \n",
    "        # Optimal lambda is that which minimizes the cross-validation error\n",
    "        self.lambda_star_index = np.argmin(self.cv_scores)\n",
    "        self.lambda_star = self.lambdas[self.lambda_star_index]\n",
    "        print(\"\\n\\n**OPTIMAL LAMBDA: {}**\".format(self.lambda_star))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda: 1\n",
      "Fold: 1. Error: 37.392059023212376\n",
      "Fold: 2. Error: 27.031973937166686\n",
      "Fold: 3. Error: 31.808349364504075\n",
      "Fold: 4. Error: 35.3249765934038\n",
      "Fold: 5. Error: 33.47635651927018\n",
      "LAMBDA AVERAGE: 33.006743087511424\n",
      "Lambda: 0.1\n",
      "Fold: 1. Error: 13.296342099781372\n",
      "Fold: 2. Error: 15.16330258262025\n",
      "Fold: 3. Error: 22.809326883447305\n",
      "Fold: 4. Error: 16.69268827098665\n",
      "Fold: 5. Error: 14.437724527977963\n",
      "LAMBDA AVERAGE: 16.47987687296271\n",
      "Lambda: 0.01\n",
      "Fold: 1. Error: 15.875773587276537\n",
      "Fold: 2. Error: 19.792239120306505\n",
      "Fold: 3. Error: 23.211085356532614\n",
      "Fold: 4. Error: 14.55547367261503\n",
      "Fold: 5. Error: 16.74129119850084\n",
      "LAMBDA AVERAGE: 18.035172587046304\n",
      "Lambda: 0.001\n",
      "Fold: 1. Error: 14.939083995771153\n",
      "Fold: 2. Error: 23.89121612228855\n",
      "Fold: 3. Error: 16.716094318718493\n",
      "Fold: 4. Error: 22.130207258550833\n",
      "Fold: 5. Error: 20.657440599210496\n",
      "LAMBDA AVERAGE: 19.666808458907905\n",
      "Lambda: 0.0001\n",
      "Fold: 1. Error: 17.49640862468514\n",
      "Fold: 2. Error: 19.860775533120542\n",
      "Fold: 3. Error: 23.504385460484766\n",
      "Fold: 4. Error: 20.95475141510653\n",
      "Fold: 5. Error: 21.62660850939069\n",
      "LAMBDA AVERAGE: 20.688585908557535\n",
      "Lambda: 1e-05\n",
      "Fold: 1. Error: 22.31929611782666\n",
      "Fold: 2. Error: 18.642821194465224\n",
      "Fold: 3. Error: 17.66202336635249\n",
      "Fold: 4. Error: 23.634389509482276\n",
      "Fold: 5. Error: 18.224388610765015\n",
      "LAMBDA AVERAGE: 20.096583759778333\n",
      "Lambda: 1e-06\n",
      "Fold: 1. Error: 15.214337825154606\n",
      "Fold: 2. Error: 18.08473568391616\n",
      "Fold: 3. Error: 16.38993800595619\n",
      "Fold: 4. Error: 20.98619403612439\n",
      "Fold: 5. Error: 24.638389292433374\n",
      "LAMBDA AVERAGE: 19.062718968716943\n",
      "\n",
      "\n",
      "**OPTIMAL LAMBDA: 0.1**\n"
     ]
    }
   ],
   "source": [
    "# User must specify lambdas over which to search\n",
    "lambdas = [1, 0.1, 0.01, 0.001, 0.0001, 0.00001, 0.000001]\n",
    "\n",
    "cross_validator = CustomCrossValidator(\n",
    "    X, Y, CustomLinearModel,\n",
    "    loss_function=mean_absolute_percentage_error\n",
    ")\n",
    "cross_validator.cross_validate(lambdas, num_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 1 is different from 35)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-b1865aa82190>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"training_set.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[0mclt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCustomLinearModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m \u001b[0mclt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[0mclt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbeta\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-2396041c3049>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, maxiter)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         res = minimize(self.l2_regularized_loss, self.beta_init,\n\u001b[1;32m---> 52\u001b[1;33m                        method='BFGS', options={'maxiter': 500})\n\u001b[0m\u001b[0;32m     53\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbeta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbeta_init\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbeta\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda\\lib\\site-packages\\scipy\\optimize\\_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    593\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_minimize_cg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'bfgs'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 595\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_minimize_bfgs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    596\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'newton-cg'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m         return _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n",
      "\u001b[1;32mD:\\Programs\\Anaconda\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36m_minimize_bfgs\u001b[1;34m(fun, x0, args, jac, callback, gtol, norm, eps, maxiter, disp, return_all, **unknown_options)\u001b[0m\n\u001b[0;32m    968\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    969\u001b[0m         \u001b[0mgrad_calls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmyfprime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwrap_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfprime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 970\u001b[1;33m     \u001b[0mgfk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmyfprime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    971\u001b[0m     \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m     \u001b[0mN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[1;34m(*wrapper_args)\u001b[0m\n\u001b[0;32m    298\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 300\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    301\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36mapprox_fprime\u001b[1;34m(xk, f, epsilon, *args)\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    729\u001b[0m     \"\"\"\n\u001b[1;32m--> 730\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_approx_fprime_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    731\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    732\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36m_approx_fprime_helper\u001b[1;34m(xk, f, epsilon, args, f0)\u001b[0m\n\u001b[0;32m    662\u001b[0m     \"\"\"\n\u001b[0;32m    663\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mf0\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 664\u001b[1;33m         \u001b[0mf0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    665\u001b[0m     \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m     \u001b[0mei\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[1;34m(*wrapper_args)\u001b[0m\n\u001b[0;32m    298\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 300\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    301\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-2396041c3049>\u001b[0m in \u001b[0;36ml2_regularized_loss\u001b[1;34m(self, beta)\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0ml2_regularized_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbeta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         return(self.model_error() + \\\n\u001b[0m\u001b[0;32m     33\u001b[0m                sum(self.regularization*np.array(self.beta)**2))\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-2396041c3049>\u001b[0m in \u001b[0;36mmodel_error\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmodel_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         error = self.loss_function(\n\u001b[1;32m---> 26\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         )\n\u001b[0;32m     28\u001b[0m         \u001b[1;32mreturn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-2396041c3049>\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[1;32mreturn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 1 is different from 35)"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import csv\n",
    "import datetime \n",
    "import calendar \n",
    "  \n",
    "\n",
    "\n",
    "def read_data(path):\n",
    "    with open(path, 'r') as f:\n",
    "        data = csv.reader(f, delimiter=',') \n",
    "        #[(y, [feature vector]),...]\n",
    "        X = []\n",
    "        Y = []\n",
    "        for i, line in enumerate(data):\n",
    "            if i == 0: #first line is title\n",
    "                continue \n",
    "            else:\n",
    "                example = []\n",
    "                Y.append(int(line[0]))\n",
    "                example.append(feature_engineer(line[1:]))\n",
    "                X.append(example)\n",
    "    return np.array(Y), np.array(X)\n",
    "\n",
    "\n",
    "\n",
    "def feature_engineer(x):\n",
    "    feature_vector = []\n",
    "\n",
    "    engagment = np.array([x[0]]) #engagment\n",
    "\n",
    "    date, time, _ = x[1].split(\" \")\n",
    "    year, month, day = date.split(\"-\")\n",
    "    day_of_week_vector = np.zeros(7) #starts on monday\n",
    "    day_of_week = datetime.date(int(year),int(month),int(day)).weekday() #0 for monday, 1 for tues...\n",
    "    day_of_week_vector[day_of_week] = 1\n",
    "\n",
    "    hours = np.zeros(24)\n",
    "    hours[int(time[:2])] = 1\n",
    "\n",
    "    medium = [\"Photo\", \"Album\", \"Video\"]\n",
    "    medium_vector = np.zeros(3)\n",
    "    medium_index = 2\n",
    "    medium_vector[medium.index(x[medium_index])] = 1\n",
    "\n",
    "    description_index = 3\n",
    "    #description_vector = generate_description_vector(x[description_index])\n",
    "    return np.concatenate((engagment, day_of_week_vector, hours, medium_vector))\n",
    "\n",
    "\n",
    "\n",
    "Y, X = read_data(\"training_set.csv\")\n",
    "clt = CustomLinearModel(X=X, Y=Y)\n",
    "clt.fit()\n",
    "clt.beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
